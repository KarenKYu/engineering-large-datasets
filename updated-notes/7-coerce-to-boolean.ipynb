{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coercing to Booleans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll work through identifying and coercing data to boolean values.  This will also prepare us to identify and coerce categorical values in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our AirBnb Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lesson, we'll work with [AirBnb listings in Berlin](https://www.kaggle.com/brittabettendorf/berlin-airbnb-data).  Let's load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./nums_and_dates_ten_k.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes('object').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_date_cols = ['last_scraped',\n",
    " 'host_since',\n",
    " 'calendar_last_scraped',\n",
    " 'first_review',\n",
    " 'last_review']\n",
    "df[potential_date_cols] = df[potential_date_cols].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 83)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lucky for us, we already have our good amount of our data already coerced.  But we still have more work to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 45)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_df = df.select_dtypes(include = 'object')\n",
    "\n",
    "object_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_date(column):\n",
    "#     remove nas first, potentially use all\n",
    "    regex_string = (r'^\\d{1,2}-\\d{1,2}-\\d{4}$|^\\d{4}-\\d{1,2}-\\d{1,2}$' + \n",
    "'|^\\d{1,2}\\/\\d{1,2}\\/\\d{4}$|^\\d{4}\\/\\d{1,2}\\/\\d{1,2}$')\n",
    "    return column.str.contains(regex_string).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a lot of our columns are still of type object.  Let's take a look at some of our object columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_different(df_series):\n",
    "    series_filled = df_series.dropna()\n",
    "    return len(series_filled.unique())/len(series_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_categorical(df, threshold = .5):    \n",
    "    categorical_df = pd.DataFrame({})\n",
    "    for column in df.columns:\n",
    "        if percent_different(df[column]) < threshold:\n",
    "            categorical_df[column] = df[column]\n",
    "    return categorical_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine with Selecting Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiple_val_counts(df, num_vals = 1):\n",
    "    return [df[column].value_counts(normalize=True).iloc[:num_vals] for column in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Anna    0.00852\n",
       " Name: host_name, dtype: float64,\n",
       " Berlin, Berlin, Germany    0.826202\n",
       " Name: host_location, dtype: float64,\n",
       " within an hour    0.457895\n",
       " Name: host_response_time, dtype: float64]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_multiple_val_counts(potential_cat)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And summarize cats, puts this information in an easier to work with numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def summarize_cats(df):\n",
    "    multiple_val_counts = get_multiple_val_counts(df)\n",
    "    stacked_counts = np.vstack([np.array([val_count.name, val_count.index[0], float(val_count.values[0])]) for val_count in multiple_val_counts])\n",
    "    sorted_cols = np.argsort(stacked_counts.reshape(-1, 3)[:, 2].astype('float'))\n",
    "    return stacked_counts[sorted_cols[::-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Boolean Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer, MissingIndicator\n",
    "steps = [([col], [SimpleImputer(strategy = 'constant', missing_values= np.nan, fill_value = 'f'),\n",
    "                  MissingIndicator(missing_values = 't')\n",
    "                 ]\n",
    "         ) \n",
    "         for col in true_boolean_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./listings_coerced_booleans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = df.dtypes.astype(str).to_dict()\n",
    "\n",
    "file = './coerced_bools_dtypes.json'\n",
    "\n",
    "with open(file, 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bed_type', 'calendar_updated', 'cancellation_policy', 'city',\n",
       "       'host_has_profile_pic', 'host_identity_verified',\n",
       "       'host_is_superhost', 'host_location', 'host_name',\n",
       "       'host_neighbourhood', 'host_response_time', 'host_verifications',\n",
       "       'market', 'neighbourhood', 'neighbourhood_cleansed',\n",
       "       'neighbourhood_group_cleansed', 'property_type', 'room_type',\n",
       "       'smart_location', 'state', 'street', 'zipcode'], dtype=object)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "remaining_cat_cols = np.setdiff1d(potential_cat.columns, bool_df.columns)\n",
    "\n",
    "remaining_cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we were introduced to some of the methods for handling boolean and categorical data.  We saw that we identified our categorical columns by looking at the percent different.  If not a large percent of a column's values are different, it is likely categorical or boolean.  We then used our `summarize_cats` method to view the top values in each of the columns, along with how often they occur.\n",
    "\n",
    "Finally, we used the `MissingImputer` to convert values in almost boolean columns to True and False values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
