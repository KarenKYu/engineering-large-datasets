{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to select a training and test set.  Remember that we want a test set that is of our most recent data so that we do not use train a model that is good at looking backwards, but not so good at projecting forwards.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by loading our data from our csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "listings_df = pd.read_csv('./price_listings_ten_k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the next thing for us to do is choose a split for our data.  The main thing here, is to make sure that we are setting up our model for the same situation it will have when we deploy the model.  Our model will be tasked with taking past data, and predicting future results, so we should split the data by datetime if appropriate.\n",
    "\n",
    "Let's look through our dataset to see if there are any datetime columns that indicate the date of a listing.  Then we can split the listings by date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If we select for datetime columns, we see that we currently don't have any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22547, 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df.select_dtypes(include = 'datetime').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can use the `contains_date` function below to search for strings that might be dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_date(column):\n",
    "#     remove nas first, potentially use all\n",
    "    regex_string = (r'^\\d{1,2}-\\d{1,2}-\\d{4}$|^\\d{4}-\\d{1,2}-\\d{1,2}$' + \n",
    "'|^\\d{1,2}\\/\\d{1,2}\\/\\d{4}$|^\\d{4}\\/\\d{1,2}\\/\\d{1,2}$')\n",
    "    return column.str.contains(regex_string).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contains_date = listings_df.apply(lambda col: contains_date(col))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>host_since</th>\n",
       "      <th>latitude</th>\n",
       "      <th>is_location_exact</th>\n",
       "      <th>property_type</th>\n",
       "      <th>calendar_last_scraped</th>\n",
       "      <th>first_review</th>\n",
       "      <th>last_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-07</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>52.5345</td>\n",
       "      <td>f</td>\n",
       "      <td>Guesthouse</td>\n",
       "      <td>2018-11-07</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>2018-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-07</td>\n",
       "      <td>2008-09-16</td>\n",
       "      <td>52.5485</td>\n",
       "      <td>t</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>2018-11-07</td>\n",
       "      <td>2018-07-04</td>\n",
       "      <td>2018-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-07</td>\n",
       "      <td>2008-10-19</td>\n",
       "      <td>52.535</td>\n",
       "      <td>t</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>2018-11-07</td>\n",
       "      <td>2009-06-20</td>\n",
       "      <td>2017-03-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  last_scraped  host_since latitude is_location_exact property_type  \\\n",
       "0   2018-11-07  2008-08-18  52.5345                 f    Guesthouse   \n",
       "1   2018-11-07  2008-09-16  52.5485                 t     Apartment   \n",
       "2   2018-11-07  2008-10-19   52.535                 t     Apartment   \n",
       "\n",
       "  calendar_last_scraped first_review last_review  \n",
       "0            2018-11-07   2016-04-11  2018-10-28  \n",
       "1            2018-11-07   2018-07-04  2018-10-01  \n",
       "2            2018-11-07   2009-06-20  2017-03-20  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df[contains_date[contains_date == True].index][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So five of the columns have dates.  But are there any columns that tell us of a later listing price.  Do you see any?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the best candidate is last scraped.  If the data was scraped on a later date, then it was likely listed a litte before then.  Let's take a look at that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-11-07    22541\n",
       "2018-11-09        3\n",
       "t                 2\n",
       "f                 1\n",
       "Name: last_scraped, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df['last_scraped'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it looks like these listing prices were all scraped on the same date.  Perhaps the other column to look at is the last review - this may tell us if there are any out of date listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010-09-16    1\n",
       "2011-01-26    1\n",
       "2011-11-14    1\n",
       "2012-07-08    1\n",
       "2012-07-17    1\n",
       "2012-07-27    1\n",
       "2012-12-17    1\n",
       "2013-06-14    1\n",
       "2013-08-13    1\n",
       "2013-09-01    1\n",
       "Name: last_review, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df['last_review'].value_counts().sort_index()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it does appear that there are some stale listings.  We may need to do more research into this.  But it seems like if a listing did not receive a review in five years, that the listing price may not have been updated in a long time.  \n",
    "\n",
    "This would be a good candidate to split our data by, but if we look at the number of null values, we se eit's quite a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3912"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df['last_review'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22547, 94)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So roughly 18 percent of the data.   We probably do not want to bias our training, validation, and test set with all of the na values just in one of those datasets.  So let's leave it alone for now.  Instead, we'll do a random split of the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = listings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22547, 94)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, random_state = 1, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4510, 94)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18037, 94)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.to_csv('x_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.reset_index().to_feather('X_train_list.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we explored how best to split of our data.  Because our task is train a model by giving it the task it will encounter when deployed, we want it to train our model to use past data to predict future outcomes.  To this end, we saw if we could sort listings by the day of the of the listing.  We saw that `last_scraped` mainly had the same date.  And we saw that `last_review`, while perhaps indicative of older listings, had many null values.  So we resorted to a random split of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[Check for multiple substrings](/Users/jeff/Documents/jigsaw/curriculum/1-section-content/mod-2/2-regression/brian-yeshiva/6-feature-lib)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
